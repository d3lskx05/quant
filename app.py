import streamlit as st
from pathlib import Path
import gdown
import os
import psutil
import time
import numpy as np
import torch
import onnxruntime as ort
from transformers import AutoTokenizer

# ========================
# üîπ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# ========================
st.set_page_config(page_title="USER-BGE-M3 ONNX Test", layout="wide")
st.title("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ USER-BGE-M3 (int8)")

MODEL_URL = "https://drive.google.com/uc?id=1lkrvCPIE1wvffIuCSHGtbEz3Epjx5R36"
MODEL_DIR = Path("onnx-user-bge-m3")
MODEL_FILE = MODEL_DIR / "model_quantized.onnx"


# ========================
# üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# ========================
@st.cache_resource
def load_model():
    MODEL_DIR.mkdir(exist_ok=True)

    if not MODEL_FILE.exists():
        st.write("üì• –°–∫–∞—á–∏–≤–∞—é –º–æ–¥–µ–ª—å —Å Google Drive...")
        gdown.download(MODEL_URL, str(MODEL_FILE), quiet=False)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º ONNX –º–æ–¥–µ–ª—å
    session = ort.InferenceSession(str(MODEL_FILE), providers=["CPUExecutionProvider"])
    tokenizer = AutoTokenizer.from_pretrained("deepvk/USER-BGE-M3")  # –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä
    return session, tokenizer


session, tokenizer = load_model()
st.success("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")


# ========================
# üìù –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
# ========================
texts = st.text_area(
    "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç(—ã) –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É):",
    "–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ.\n–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏."
).split("\n")

if st.button("üîç –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å"):
    process = psutil.Process(os.getpid())

    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ
    cpu_before = psutil.cpu_percent(interval=1)
    mem_before = process.memory_info().rss / (1024 ** 2)

    start = time.perf_counter()

    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="np")

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–æ–≤ –¥–ª—è ONNX
    ort_inputs = {k: v for k, v in inputs.items()}

    # –ü—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
    ort_outputs = session.run(None, ort_inputs)
    embeddings = ort_outputs[0].mean(axis=1)

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
    embeddings = embeddings / norms

    end = time.perf_counter()

    # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ
    cpu_after = psutil.cpu_percent(interval=1)
    mem_after = process.memory_info().rss / (1024 ** 2)

    # ========================
    # üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    # ========================
    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")
    st.write(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: **{end - start:.3f} —Å–µ–∫**")
    st.write(f"üî¢ –†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: **{embeddings.shape}**")
    st.write("üìÑ –ü–µ—Ä–≤—ã–µ 10 –∑–Ω–∞—á–µ–Ω–∏–π –ø–µ—Ä–≤–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞:")
    st.json(embeddings[0][:10].tolist())

    st.subheader("üìà –†–µ—Å—É—Ä—Å—ã")
    col1, col2, col3 = st.columns(3)
    col1.metric("CPU –¥–æ (%)", f"{cpu_before:.1f}")
    col2.metric("CPU –ø–æ—Å–ª–µ (%)", f"{cpu_after:.1f}")
    col3.metric("–ü–∞–º—è—Ç—å (MB)", f"{mem_after:.1f}")

    st.success("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
