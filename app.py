import streamlit as st
from pathlib import Path
import gdown
import os
import psutil
import time
import torch
import numpy as np
from transformers import AutoTokenizer
from optimum.onnxruntime import ORTModelForFeatureExtraction

# ========================
# üîπ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# ========================
st.set_page_config(
    page_title="USER-BGE-M3 Quantized ONNX Test",
    layout="wide"
)
st.title("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ USER-BGE-M3 (int8)")

MODEL_URL = "https://drive.google.com/uc?id=1lkrvCPIE1wvffIuCSHGtbEz3Epjx5R36"
MODEL_DIR = Path("onnx-user-bge-m3")
MODEL_FILE = MODEL_DIR / "model_quantized.onnx"


# ========================
# üì• –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
# ========================
@st.cache_resource
def load_model_and_tokenizer():
    MODEL_DIR.mkdir(exist_ok=True)

    if not MODEL_FILE.exists():
        st.write("üì• –°–∫–∞—á–∏–≤–∞—é –º–æ–¥–µ–ª—å —Å Google Drive...")
        gdown.download(MODEL_URL, str(MODEL_FILE), quiet=False)

    st.write("‚öôÔ∏è –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å...")
    model = ORTModelForFeatureExtraction.from_pretrained(MODEL_DIR, file_name=MODEL_FILE.name)
    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
    return model, tokenizer


# ========================
# üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# ========================
model, tokenizer = load_model_and_tokenizer()
st.success("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")


# ========================
# üìù –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
# ========================
texts = st.text_area(
    "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç(—ã) –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É):",
    "–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ.\n–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏."
).split("\n")


if st.button("üîç –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å"):
    process = psutil.Process(os.getpid())

    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ
    cpu_before = psutil.cpu_percent(interval=1)
    mem_before = process.memory_info().rss / (1024 ** 2)

    start_time = time.perf_counter()

    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt")

    # –ü—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
    with torch.no_grad():
        outputs = model(**inputs)
        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
    embeddings = embeddings / norms

    end_time = time.perf_counter()

    # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ
    cpu_after = psutil.cpu_percent(interval=1)
    mem_after = process.memory_info().rss / (1024 ** 2)

    # ========================
    # üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    # ========================
    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")
    st.write(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: **{end_time - start_time:.3f} —Å–µ–∫**")
    st.write(f"üî¢ –†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: **{embeddings.shape}**")
    st.write("üìÑ –ü–µ—Ä–≤—ã–µ 10 –∑–Ω–∞—á–µ–Ω–∏–π –ø–µ—Ä–≤–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞:")
    st.json(embeddings[0][:10].tolist())

    st.subheader("üìà –†–µ—Å—É—Ä—Å—ã")
    col1, col2, col3 = st.columns(3)
    col1.metric("CPU –¥–æ (%)", f"{cpu_before:.1f}")
    col2.metric("CPU –ø–æ—Å–ª–µ (%)", f"{cpu_after:.1f}")
    col3.metric("–ü–∞–º—è—Ç—å (MB)", f"{mem_after:.1f}")

    st.success("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
