import streamlit as st
from pathlib import Path
import gdown
import zipfile
import os
import psutil
import time
import numpy as np
import torch
import onnxruntime as ort
from transformers import AutoTokenizer

# ========================
# üîπ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# ========================
st.set_page_config(page_title="USER-BGE-M3 ONNX Test", layout="wide")
st.title("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ USER-BGE-M3 (int8)")

# –°—Å—ã–ª–∫–∞ –Ω–∞ ZIP-–∞—Ä—Ö–∏–≤ –≤ GDrive
MODEL_URL = "https://drive.google.com/uc?id=1lkrvCPIE1wvffIuCSHGtbEz3Epjx5R36"
ZIP_PATH = Path("user_bge_m3.zip")
MODEL_DIR = Path("onnx-user-bge-m3")
MODEL_FILE = MODEL_DIR / "model_quantized.onnx"


# ========================
# üì• –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏
# ========================
@st.cache_resource
def load_model():
    # 1. –°–∫–∞—á–∏–≤–∞–µ–º ZIP, –µ—Å–ª–∏ –Ω–µ—Ç
    if not ZIP_PATH.exists():
        st.write("üì• –°–∫–∞—á–∏–≤–∞—é –∞—Ä—Ö–∏–≤ –º–æ–¥–µ–ª–∏...")
        gdown.download(MODEL_URL, str(ZIP_PATH), quiet=False, fuzzy=True)

    # 2. –†–∞—Å–ø–∞–∫–æ–≤–∫–∞
    if not MODEL_FILE.exists():
        st.write("üì¶ –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞—é –º–æ–¥–µ–ª—å...")
        with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:
            zip_ref.extractall(MODEL_DIR)

    # 3. –ó–∞–≥—Ä—É–∑–∫–∞ ONNX
    st.write("‚öôÔ∏è –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å...")
    session = ort.InferenceSession(str(MODEL_FILE), providers=["CPUExecutionProvider"])

    # 4. –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä —Å HuggingFace Hub
    tokenizer = AutoTokenizer.from_pretrained("deepvk/USER-BGE-M3")

    return session, tokenizer


# ========================
# üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# ========================
session, tokenizer = load_model()
st.success("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")


# ========================
# üìù –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
# ========================
texts = st.text_area(
    "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç(—ã) –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É):",
    "–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ.\n–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏."
).split("\n")

if st.button("üîç –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å"):
    process = psutil.Process(os.getpid())

    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ
    cpu_before = psutil.cpu_percent(interval=1)
    mem_before = process.memory_info().rss / (1024 ** 2)

    start = time.perf_counter()

    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="np")

    # –ü—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ ONNX
    ort_inputs = {k: v for k, v in inputs.items()}
    ort_outputs = session.run(None, ort_inputs)
    embeddings = ort_outputs[0].mean(axis=1)

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
    embeddings = embeddings / norms

    end = time.perf_counter()

    # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ
    cpu_after = psutil.cpu_percent(interval=1)
    mem_after = process.memory_info().rss / (1024 ** 2)

    # ========================
    # üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    # ========================
    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")
    st.write(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: **{end - start:.3f} —Å–µ–∫**")
    st.write(f"üî¢ –†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: **{embeddings.shape}**")
    st.write("üìÑ –ü–µ—Ä–≤—ã–µ 10 –∑–Ω–∞—á–µ–Ω–∏–π –ø–µ—Ä–≤–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞:")
    st.json(embeddings[0][:10].tolist())

    st.subheader("üìà –†–µ—Å—É—Ä—Å—ã")
    col1, col2, col3 = st.columns(3)
    col1.metric("CPU –¥–æ (%)", f"{cpu_before:.1f}")
    col2.metric("CPU –ø–æ—Å–ª–µ (%)", f"{cpu_after:.1f}")
    col3.metric("–ü–∞–º—è—Ç—å (MB)", f"{mem_after:.1f}")

    st.success("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
